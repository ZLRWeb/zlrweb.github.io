---
slug: tech-summary-2025-10-14
title: TechSummary 2025-10-14
authors: gemini
tags: [GitHub Copilot, AI Agents, Legacy Modernization, COBOL, Microsoft Semantic Kernel, Azure Samples, Multi-Agent Systems, cagent, Docker, AI Orchestration, Open Source, Docker Model Runner, NVIDIA DGX Spark, Local AI Development, GPU Acceleration, JetBrains MPS, Bug Fixes, ReSharper, Visual Studio Code, Open VSX Registry, C# Development]
---

# TechSummary 2025-10-14

## 💻 GitHub Copilot 與 AI 代理如何拯救傳統系統

**Source:** https://github.blog/ai-and-ml/github-copilot/how-github-copilot-and-ai-agents-are-saving-legacy-systems/

-   **挑戰與機遇：** 傳統 COBOL 系統（65年歷史，支援銀行、保險等關鍵業務）面臨開發者短缺問題。GitHub Copilot 及自主 AI 代理提供現代化解決方案，無需掌握 COBOL 即可進行系統更新。
-   **微軟 Julia Kordick 的三步驟框架：**
    1.  **程式碼準備 (逆向工程)：** 利用 GitHub Copilot 從傳統檔案中提取業務邏輯、生成 Markdown 文件、識別呼叫鏈和依賴關係，並清理無關註釋。
        ```
        # Business Logic Analysis Generated by GitHub Copilot
        ## File Inventory
        - listings.cobol: List management functionality (~100 lines)
        - mainframe-example.cobol: Full mainframe program (~10K lines, high complexity)

        ## Business Purpose
        Customer account validation with balance checking
        - Validates account numbers against master file
        - Performs balance calculations with overdraft protection
        - Generates transaction logs for audit compliance

        ## Dependencies Discovered
        - DB2 database connections via SQLCA
        - External validation service calls
        - Legacy print queue system
        ```
    2.  **內容強化 (使 AI 易於理解)：** 翻譯非英文註釋、利用 COBOL 程式的固定分區結構（IDENTIFICATION、ENVIRONMENT、DATA、PROCEDURE DIVISION）讓 AI 進行分析，並將 AI 生成的文檔儲存為主要參考依據。
        ```
        "Identify all the divisions in this COBOL file and summarize what each one does"
        "List all data structures defined in the DATA DIVISION and their purpose"
        "Extract the main business logic flow from the PROCEDURE DIVISION"
        ```
    3.  **自動化輔助 (擴展流程)：** 從互動式 Copilot 應用轉向 AI 代理自動化工作流，使用 Microsoft Semantic Kernel 協調多個專門代理，實現呼叫鏈映射（生成 Mermaid 圖）、測試驅動現代化和依賴優化。
-   **局限性與實際應用：** AI 並非萬靈丹，人類專家仍需參與驗證。微軟開源了 Azure Samples 框架 (aka.ms/cobol)，包含專門代理、成本追蹤及人工驗證點，幫助開發者快速啟動現代化進程。
    ```bash
    git clone https://github.com/Azure-Samples/Legacy-Modernization-Agents
    cd Legacy-Modernization-Agents
    ./doctor.sh setup
    ./doctor.sh run
    ```
-   **商業價值：** AI 驅動的方法能幫助企業保留知識產權、生成可維護的現代程式碼，並讓開發團隊在現代化過程中學習業務邏輯，解決傳統方法中高成本、低可維護性的問題。

<!-- truncate -->

## 🤖 使用 cagent 在 5 分鐘內建構多代理系統

**Source:** https://www.docker.com/blog/how-to-build-a-multi-agent-system/

-   **多代理系統的興起：** 隨著 AI 模型快速發展，單一模型已無法解決所有複雜任務，因此需要由協調運作的 AI 代理群組（如研究員、作者、規劃師、審閱者）來完成複雜任務。
-   **cagent 解決方案：** cagent 是 Docker 開源工具，能以宣告式 YAML 文件定義代理或代理團隊，無需複雜的膠水程式碼即可協調模型、工具和工作流，讓代理成為可移植、可重現的產物。
-   **cagent 的核心優勢：**
    -   **簡化代理協調：** 透過 YAML 定義角色和委派（子代理），cagent 管理呼叫和上下文流。
    -   **工具使用與安全：** 透過 MCP (Model-Controller-Policy) 機制為代理提供搜尋、GitHub、文件、資料庫等能力，並確保可稽核性。
    -   **模型互換性：** 支援 OpenAI、Anthropic、Gemini 或透過 Docker Model Runner 支援本地模型，無需重寫系統即可更換供應商。
    -   **代理即文物：** 像容器一樣打包、版本化和共享代理。
-   **如何使用 cagent 建構多代理系統：**
    1.  **定義多代理系統：** 在 YAML 文件中定義協調者、研究員和作者等代理的角色、使用的模型及工具。
    2.  **執行 YAML 文件：** 透過 `cagent run ./team.yaml` 命令啟動代理系統。
    3.  **分享到 Docker Hub：** 使用 `cagent push ./team.yaml org/research-writer` 將定義推送到 Docker Hub，團隊成員即可輕鬆運行。
-   **應用場景：** PR 和問題分類、研究總結、知識路由等。每個應用都從 YAML 文件和一個想法開始，並可被推送至註冊中心供任何人運行。
    ```bash
    # 快速啟動
    docker extension install cagent/cagent
    cagent init team.yaml
    cagent run team.yaml
    ```

## 🎉 重啟 Docker Model Runner 社群！

**Source:** https://www.docker.com/blog/rebooting-model-runner-community/

-   **全面可用 (GA) 與擴展支援：** Docker Model Runner 現已普遍可用 (GA)，並支援所有 Docker 版本，不僅限於 Docker Desktop。更重要的是，新增了 Vulkan 支援，讓模型幾乎可以在任何 GPU 上運行。
-   **簡化貢獻流程：** Docker 團隊聽取了社群反饋，將所有儲存庫合併到一個統一的平台，並更新了貢獻者文件，讓開源貢獻變得更加便捷。
-   **邀請社群參與：** 鼓勵用戶通過加星、分叉代碼庫並提交拉取請求，以及分享消息來支持 Docker Model Runner，共同塑造其未來。

## 🖥️ Docker Model Runner 與 NVIDIA DGX Spark：本地 AI 開發新典範

**Source:** https://www.docker.com/blog/new-nvidia-dgx-spark-docker-model-runner/

-   **NVIDIA DGX Spark 簡介：** 新推出的 DGX Spark 是一款緊湊型工作站級 AI 系統，搭載 Grace Blackwell GB10 Superchip，為本地模型開發提供卓越性能，無需依賴雲端即可快速進行原型設計、微調和模型服務。
-   **本地 AI 優勢與挑戰：** 本地運行 AI 模型具有數據隱私、離線可用性和易於客製化的優勢，但存在 GPU/記憶體限制、設定複雜和安全性管理的挑戰。
-   **DGX Spark + Docker Model Runner 的解決方案：** 結合 DGX Spark 的強大硬體與 Docker Model Runner 的沙盒環境和 Docker 體驗，提供即插即用的 GPU 加速和 Docker 級的簡潔性，解決了本地 AI 開發的痛點。
-   **在 DGX Spark 上安裝 Docker Model Runner：**
    1.  **驗證 Docker CE：** 確認已安裝 Docker Engine (CE)。
        ```bash
        docker version
        ```
    2.  **安裝 Docker Model CLI Plugin：**
        ```bash
        sudo apt-get update
        sudo apt-get install docker-model-plugin
        # 或使用安裝腳本
        # curl -fsSL https://download.docker.com/linux/ubuntu/model-runner/install | sh
        ```
    3.  **拉取並運行模型：** 從 Docker Hub AI 目錄拉取模型（例如 Qwen 3 Coder），Model Runner 容器會自動暴露 OpenAI-compatible 端點 (`http://localhost:12434/engines/v1`)。
        ```bash
        docker model pull ai/qwen3-coder
        # 測試 API
        curl http://localhost:12434/engines/v1/chat/completions -H 'Content-Type: application/json' -d '{"model":"ai/qwen3-coder","messages":[{"role":"user","content":"Hello!"}]}'
        # 或透過 CLI
        docker model run ai/qwen3-coder
        ```
-   **本地模型在日常工作流中的應用：** 可將 DGX Spark 作為遠端模型主機，透過 SSH 隧道轉發 Model Runner API 端口和 DGX 儀表板端口，實現無縫的本地 AI 開發體驗。
    ```bash
    # 轉發 DMR 端口 (模型存取)
    ssh -L 12434:localhost:12434 user@dgx-spark.local
    # 轉發 DGX 儀表板端口 (監控)
    ssh -L 11000:localhost:11000 user@dgx-spark.local
    ```
-   **範例應用：** 配置 OpenCode 使用 DGX Spark 上運行的 Qwen3-Coder 模型，實現本地 AI 代理編碼體驗，同時監控 GPU 使用情況。
-   **總結：** DGX Spark 與 Docker Model Runner 的結合，提供了一種實用且開發者友好的方式，將強大的 AI 計算能力帶到開發者桌面，同時兼顧速度、隱私和靈活性。

## 🐞 MPS 新錯誤修正版本發布 – 2025.2.1, 2025.1.1, 2024.3.4, 和 2024.1.5

**Source:** https://blog.jetbrains.com/mps/2025/10/new_bugfix_releases_mps-2025-2/

-   **多版本更新：** JetBrains MPS 發布了多個主要版本的錯誤修正更新，包括 2025.2.1、2025.1.1、2024.3.4 和 2024.1.5。
-   **主要改進：**
    -   **MPS-38681：** 隱形引用現在可以從使用高亮中排除。
    -   **MPS-36481：** Ant 中的 `<generate>` 任務現在識別兩個額外的專案屬性，用於配置日誌文件位置：`mps.log.config.file` 指向 JUL 屬性文件，`mps.log.dir` 指定日誌文件目錄。
-   **特定版本修正：** 2024.1.5 版本修正了因緩存失效而偶爾導致凍結的問題 (MPS-37659)。

## 🌐 ReSharper 現已登陸 Open VSX Registry

**Source:** https://blog.jetbrains.com/dotnet/2025/10/14/resharper-open-vsx/

-   **解決安裝不便：** 過去，使用 VS Code 相容編輯器（如 Cursor, Windsurf, VSCodium）的 ReSharper 用戶需要手動下載 .vsix 文件並自行更新，流程繁瑣。
-   **登陸 Open VSX Registry：** 為改善用戶體驗，ReSharper 現已發布到 Open VSX Registry，成為 VS Code 相容編輯器的預設市場，用戶可直接在擴充功能視圖中搜尋並安裝，並獲得自動更新。
-   **新的擴充功能架構：** 由於 Open VSX Registry 對發布二進位文件大小設有 256MB 限制，ReSharper 重新設計了擴充功能架構，採用輕量級核心，在首次啟動時從 JetBrains 伺服器下載較大的組件（如 ReSharper 語言伺服器和 .NET 運行時）。
-   **新架構的影響：**
    -   首次啟動時間會較長，因為需要下載和解壓縮組件。
    -   首次打開 .NET 解決方案時需要活躍的網路連接和對 `https://download.jetbrains.com` 伺服器的無限制訪問。離線用戶仍可下載包含所有組件的平台特定 .vsix 文件進行安裝。